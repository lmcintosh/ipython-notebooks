{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Using new numbers from Steve 5-18 2017  \n",
    "(e.g. horizontal and amacrine space constants)  \n",
    "Amacrine cell 80 ± 18 µm (mean ± sd)  \n",
    "Horizontal cell 116  ±  35  \n",
    "Bipolar cell SNR 7.1 ± 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "\n",
    "import numpy as np\n",
    "import collections\n",
    "from functools import partial\n",
    "from os.path import expanduser\n",
    "from tqdm import tqdm\n",
    "import h5py\n",
    "\n",
    "from surround.image_processing import *\n",
    "from surround.data_handling import *\n",
    "from surround.efficient_coding import *\n",
    "from aesthetics.plotting import *\n",
    "from surround.modeling import gaussian, difference_of_gaussians\n",
    "\n",
    "import pyret.filtertools as ft\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.stats import sem\n",
    "from scipy.optimize import curve_fit, minimize\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from scipy.signal import convolve2d\n",
    "\n",
    "# This is a bit of magic to make matplotlib figures appear inline in the\n",
    "# notebook rather than in a new window.\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MultipleLocator, FormatStrFormatter\n",
    "\n",
    "plt.style.use('deepretina')\n",
    "\n",
    "# Some more magic so that the notebook will reload external python modules;\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "microns_per_degree = 50.0 # depends on species; this is for salamander\n",
    "photoreceptor_width = 10.0/microns_per_degree # salamander photoreceptors have width of 10-20 microns\n",
    "retina_width = 4000.0/microns_per_degree # salamander retina is about 4 mm\n",
    "frequency_spacing = 1./retina_width # this is the lowest non-DC frequency we can estimate\n",
    "highest_frequency = 0.5/photoreceptor_width # this is the highest frequency we can estimate (Nyquist freq.)\n",
    "\n",
    "N = int(retina_width//photoreceptor_width)\n",
    "freqs = np.linspace(0, highest_frequency, N//2 + 1)\n",
    "space = np.concatenate([np.linspace(-0.5*retina_width, 0, N//2 + 1)[:-1], np.linspace(0, 0.5*retina_width, N//2 + 1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Load receptive fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# These are loaded as (space, receptive) field tuples\n",
    "cells = {}\n",
    "cells['ganglion'] = load_ganglion_cells(space_mode='peak')\n",
    "cells['bipolar'] = load_bipolar_cells(space_mode='peak')\n",
    "cells['amacrine'] = load_amacrine_cells(space_mode='peak')\n",
    "cells['horizontal'] = load_horizontal_cells(space_mode='peak')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "receptive_fields = collections.defaultdict(list)\n",
    "for c in cells.keys():\n",
    "    for s, rf in cells[c]:\n",
    "        this_cell_interp = interp1d(s, rf, kind='slinear', bounds_error=False, fill_value=[0])\n",
    "        receptive_fields[c].append(this_cell_interp(space))\n",
    "        \n",
    "average_ganglion_rf = np.mean(receptive_fields['ganglion'], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "David's 1721 receptive field dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "data_path = expanduser('~/data/kastner/receptive_fields/')\n",
    "spatialDelta = 0.05 # mm\n",
    "micronsPerDeg = 50.\n",
    "ganglion_rfs = {\n",
    "    'fast_on': np.loadtxt(data_path + 'linesRF1.txt').reshape((126, 101, -1)),\n",
    "    'fast_off_adapting': np.loadtxt(data_path + 'linesRF19.txt').reshape((-1, 101, 96)),\n",
    "    'fast_off_sensitizing': np.loadtxt(data_path + 'linesRF8.txt').reshape((-1, 101, 96)),\n",
    "    'medium_off_adapting': np.loadtxt(data_path + 'linesRF29.txt').reshape((-1, 101, 96)),\n",
    "    'slow_off': np.loadtxt(data_path + 'linesRF17.txt').reshape((-1, 101, 96)),\n",
    "}\n",
    "\n",
    "for celltype in ganglion_rfs.keys():\n",
    "    for rf in ganglion_rfs[celltype]:\n",
    "        # since receptive fields are noisy, use PCA\n",
    "        pca = PCA(n_components=2)\n",
    "        pca.fit(rf)\n",
    "        g_pca = pca.components_[0]\n",
    "\n",
    "        sign_of_pc = -1 * np.sign(g_pca[abs(g_pca) == np.max(abs(g_pca))])\n",
    "        this_space = get_space(g_pca, spatialDelta, micronsPerDeg, kind='peak')\n",
    "        \n",
    "        rf_interp = interp1d(this_space, sign_of_pc*g_pca, kind='slinear', bounds_error=False, fill_value=[0])\n",
    "\n",
    "        receptive_fields[celltype].append(rf_interp(space))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Remove duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "corr_map = {}\n",
    "for celltype in receptive_fields.keys():\n",
    "    corr_map[celltype] = np.zeros((len(receptive_fields[celltype]), len(receptive_fields[celltype])))\n",
    "    for idr1, rf1 in tqdm(enumerate(receptive_fields[celltype])):\n",
    "        for idr2 in range(idr1+1, len(receptive_fields[celltype])):\n",
    "            rf2 = receptive_fields[celltype][idr2]\n",
    "            corr_map[celltype][idr1, idr2] = pearsonr(rf1, rf2)[0]\n",
    "\n",
    "unduplicated_receptive_fields = collections.defaultdict(list)\n",
    "duplicates = collections.defaultdict(list)\n",
    "\n",
    "for celltype in corr_map.keys():\n",
    "    these_dups = []\n",
    "    for row in corr_map[celltype]:\n",
    "        these_dups.append([i for i in range(len(row)) if row[i] == 1.0])\n",
    "    duplicates[celltype] = np.unique(np.hstack(these_dups))\n",
    "    \n",
    "unduplicated_receptive_fields = collections.defaultdict(list)\n",
    "for celltype in receptive_fields.keys():\n",
    "    for idr, rf in enumerate(receptive_fields[celltype]):\n",
    "        if idr not in duplicates[celltype]:\n",
    "            unduplicated_receptive_fields[celltype].append(rf)\n",
    "            \n",
    "receptive_fields = unduplicated_receptive_fields.copy()\n",
    "del unduplicated_receptive_fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sum([len(receptive_fields[k]) for k in receptive_fields.keys()]) - sum([len(receptive_fields[k]) for k in ['horizontal',\n",
    "                                                                                                           'amacrine',\n",
    "                                                                                                          'bipolar']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Compute projective fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "horz_pfs_full = get_horizontal_projective_field(conv_mode='full')\n",
    "horz_pfs_same = get_horizontal_projective_field(conv_mode='same')\n",
    "ama_pfs_full = get_amacrine_projective_field(conv_mode='full')\n",
    "ama_pfs_same = get_amacrine_projective_field(conv_mode='same')\n",
    "\n",
    "space_h_full, horz_pf_full, horz_sem_full = get_mean(horz_pfs_full)\n",
    "space_h_same, horz_pf_same, horz_sem_same = get_mean(horz_pfs_same)\n",
    "space_a_full, ama_pf_full, ama_sem_full = get_mean(ama_pfs_full)\n",
    "space_a_same, ama_pf_same, ama_sem_same = get_mean(ama_pfs_same)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "horz_pf_interp = interp1d(space_h_full, horz_pf_full, kind='slinear', bounds_error=False, fill_value=[0])\n",
    "ama_pf_interp = interp1d(space_a_full, ama_pf_full, kind='slinear', bounds_error=False, fill_value=[0])\n",
    "\n",
    "horz_pf = horz_pf_interp(space)\n",
    "ama_pf = ama_pf_interp(space)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# choose an image path from cd13A (flood plain, water, horizon) or cd01A (baboons, trees, bushes)\n",
    "pixelsToDeg = 92./2 # or 2./92 degrees per pixel (spacing)\n",
    "spacing = 1./pixelsToDeg # number of degree spacing between pixels\n",
    "normalize = 'divisive'\n",
    "contrast = 0.35\n",
    "signal = np.array(np.load('signal_3_23.npy'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Noise  \n",
    "Note that the amplitude of the average_ganglion_fft will change the SNR. As the amplitude $\\rightarrow \\infty$, we get $$\\rm{SNR} \\rightarrow \\frac{\\sum (\\rm{filter}_{1:f} \\times \\rm{signal}_{1:f})^2}{\\sum (\\rm{filter}_{1:f} \\times N_{\\rm{in}})^2}$$.  \n",
    "\n",
    "Since the scale of the ganglion fft is arbitrary, we can look at the SNR in this limit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "input_noise = 0.0469253741641 #0.098762200628786892\n",
    "output_noise = 0.35\n",
    "target_power = 48.053365503112332 #54.131410989171826"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "fig = plt.gcf()\n",
    "fig.set_size_inches((2,2))\n",
    "average_ganglion_fft = abs(np.fft.rfft(average_ganglion_rf))\n",
    "print(get_snr(input_noise, output_noise, signal, 1000*average_ganglion_fft, mode='variance'))\n",
    "snrs = [get_snr(input_noise, output_noise, signal, c*average_ganglion_fft) for c in np.linspace(0,50,100)]\n",
    "plt.plot(np.linspace(0,50,100), snrs)\n",
    "adjust_spines(plt.gca())\n",
    "plt.xlabel('Arbitrary scaling of ganglion cell filter')\n",
    "plt.ylabel('SNR')\n",
    "\n",
    "# SNR = 0.269 is total SNR from ganglion recordings of 112 repeats to 30 seconds natural scenes\n",
    "def find_filt_const(filt_const):\n",
    "    this_snr = get_snr(input_noise, output_noise, signal, filt_const*average_ganglion_fft, mode='variance')\n",
    "    return (this_snr - 0.26912469)**2\n",
    "\n",
    "filt_const_opt = scipy.optimize.minimize_scalar(find_filt_const)\n",
    "\n",
    "our_snr = get_snr(input_noise, output_noise, signal, filt_const_opt.x*average_ganglion_fft, mode='variance')\n",
    "\n",
    "plt.scatter(filt_const_opt.x, our_snr, s=20, color='k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Ideal filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "ideal_filter = unique_soln(signal**2, input_noise, output_noise)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Model of Horizontal Projective Field + Amacrine Projective Field + Center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "horz_pf /= np.sum(horz_pf)\n",
    "ama_pf /= np.sum(ama_pf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Just a simple difference of Gaussians fit to get the initialization point for center width, and the mean center width to find the ideal fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Get center widths for each celltype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "diff_of_gauss_mu0 = partial(difference_of_gaussians, mu=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def center_and_surround(space, center_width, surround_width, center_strength, surround_strength):\n",
    "    return diff_of_gauss_mu0(space, abs(center_width), abs(surround_width),\n",
    "                            -abs(center_strength), abs(surround_strength))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "center_widths = collections.defaultdict(list)\n",
    "surround_widths = collections.defaultdict(list)\n",
    "center_strengths = collections.defaultdict(list)\n",
    "surround_strengths = collections.defaultdict(list)\n",
    "fit_failures = collections.defaultdict(list)\n",
    "\n",
    "for celltype in receptive_fields.keys():\n",
    "    if celltype in ['ganglion', 'fast_on', 'fast_off_adapting', 'fast_off_sensitizing', \n",
    "                    'medium_off_adapting', 'slow_off']:\n",
    "        \n",
    "        for idg, g in tqdm(enumerate(receptive_fields[celltype])):\n",
    "            try:\n",
    "                popt_this, pcov = curve_fit(center_and_surround, space, g, p0=[1.5, 3.5, -10, 30])\n",
    "                center_id = np.argmin(abs(popt_this[:2]))\n",
    "                surround_id = 1 ^ center_id\n",
    "                center_widths[celltype].append(abs(popt_this[center_id]))\n",
    "                surround_widths[celltype].append(abs(popt_this[surround_id]))\n",
    "                center_strengths[celltype].append(popt_this[center_id+2])\n",
    "                surround_strengths[celltype].append(popt_this[surround_id+2])\n",
    "#                 plt.plot(space, diff_of_gauss_mu0(space, *popt_this), color=np.random.rand(3), alpha=0.6)\n",
    "            except:\n",
    "                fit_failures[celltype].append(idg)\n",
    "            \n",
    "                # just set params to median across cells\n",
    "                # this way the params are still aligned with the receptive field id\n",
    "                center_widths[celltype].append(np.median(center_widths[celltype]))\n",
    "                surround_widths[celltype].append(np.median(surround_widths[celltype]))\n",
    "                center_strengths[celltype].append(np.median(center_strengths[celltype]))\n",
    "                surround_strengths[celltype].append(np.median(surround_strengths[celltype]))\n",
    "                \n",
    "#                 print(\"Couldn't fit cell %d\" %idg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "for f in fit_failures.keys():\n",
    "    print(\"couldn't fit %d in %s\" %(len(fit_failures[f]), f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Plot the average profile across celltypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "median_center_widths = {}\n",
    "for celltype in center_widths.keys():\n",
    "    cws = np.array(center_widths[celltype])\n",
    "    sws = np.array(surround_widths[celltype])\n",
    "    css = np.array(center_strengths[celltype])\n",
    "    sss = np.array(surround_strengths[celltype])\n",
    "#     mean_center_widths[celltype] = np.mean(cws[cws < 500])\n",
    "#     mean_surround_width = np.mean(sws[sws < 500])\n",
    "#     mean_center_strength = np.mean(css[abs(css) < 500])\n",
    "#     mean_surround_strength = np.mean(sss[abs(sss) < 500])\n",
    "    \n",
    "    median_center_widths[celltype] = np.median(abs(cws))\n",
    "    median_surround_width = np.median(abs(sws))\n",
    "    median_center_strength = np.median(-abs(css))\n",
    "    median_surround_strength = np.median(abs(sss))\n",
    "#     plt.plot(space, diff_of_gauss_mu0(space, median_center_widths[celltype], median_surround_width,\n",
    "#                                      median_center_strength, median_surround_strength), label=celltype)\n",
    "# plt.legend(frameon=False, fontsize=9, loc='lower left')\n",
    "# adjust_spines(plt.gca())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "median_center_widths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Bar charts to visualize diversity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Generate info maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "resolution = 150\n",
    "horz_weights = np.linspace(0,1,resolution)\n",
    "center_weights = np.linspace(0,1,resolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "init_filt_const = 10.9\n",
    "info_maps = collections.defaultdict(list) # one info map per celltype (since they will be a function of center width)\n",
    "failures = collections.defaultdict(list)\n",
    "detailed_failures = collections.defaultdict(list)\n",
    "for celltype in receptive_fields.keys():\n",
    "    if celltype in ['ganglion', 'fast_on', 'fast_off_adapting', 'fast_off_sensitizing', \n",
    "                    'medium_off_adapting', 'slow_off']:\n",
    "        center = gaussian(x=space, sigma=median_center_widths[celltype], mu=0.)\n",
    "        center /= -np.sum(center) # make center unit vector like horz_pf and ama_pf\n",
    "        \n",
    "        def rf_model(horz_weight, center_weight):\n",
    "            return center_weight*center + (1-center_weight)*(horz_weight*horz_pf + (1-horz_weight)*ama_pf)\n",
    "        \n",
    "#         print('Information map for %s cells.' %celltype)\n",
    "        \n",
    "        infomap = np.zeros((resolution, resolution))\n",
    "        for idh,hw in tqdm(enumerate(horz_weights)):\n",
    "            for idc,cw in enumerate(center_weights):\n",
    "                rf = rf_model(hw, cw)\n",
    "                rf_filt = abs(np.fft.rfft(rf))\n",
    "                \n",
    "                # constrain model\n",
    "                def constrain_filt_power(filt_const):\n",
    "                    size = len(rf_filt)\n",
    "                    output_power = np.sum((signal*filt_const*rf_filt)**2 \n",
    "                                          + (input_noise*filt_const*rf_filt)**2\n",
    "                                          + output_noise**2)\n",
    "                    \n",
    "                    return (target_power - output_power)**2\n",
    "\n",
    "                filt_const_opt = scipy.optimize.minimize(constrain_filt_power, init_filt_const)\n",
    "                iterations = 0\n",
    "                new_init_filt_const = init_filt_const\n",
    "                while not filt_const_opt.success:\n",
    "                    iterations += 1\n",
    "                    new_init_filt_const *= 10\n",
    "                    filt_const_opt = scipy.optimize.minimize(constrain_filt_power, new_init_filt_const)\n",
    "                    if iterations > 10:\n",
    "                        detailed_failures[celltype] = filt_const_opt\n",
    "                        break\n",
    "                \n",
    "                filt_const = abs(filt_const_opt['x'])\n",
    "                \n",
    "                if not filt_const_opt.success:\n",
    "                    failures[celltype].append([hw, cw])\n",
    "\n",
    "                signal_power = (filt_const * rf_filt * signal)**2\n",
    "                noise_power = (filt_const * rf_filt * input_noise)**2 + output_noise**2\n",
    "                infomap[idh,idc] = 0.5*np.sum(np.log2(1 + signal_power/noise_power))\n",
    "        info_maps[celltype] = infomap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Fit cells to rf_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "colorscheme = {\n",
    "    'ganglion': 'k',\n",
    "    'fast_off_sensitizing': 'r',\n",
    "    'fast_off_adapting': 'g',\n",
    "    'slow_off': 'y',\n",
    "    'fast_on': 'b',\n",
    "    'medium_off_adapting': 'c'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "info_maps.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Load receptive field model fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1./(1. + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# fits = np.load('fits_3_23.npy').item()\n",
    "# all_params = np.load('params_3_23.npy').item()\n",
    "# variances = np.load('variances_3_23.npy').item()\n",
    "# mean_squared_errors = np.load('mse_3_23.npy').item()\n",
    "# abs_errors = np.load('abserrs_3_23.npy').item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "iterations = 25\n",
    "\n",
    "fits = collections.defaultdict(list)\n",
    "all_params = collections.defaultdict(list)\n",
    "mean_squared_errors = collections.defaultdict(list)\n",
    "abs_errors = collections.defaultdict(list)\n",
    "variances = collections.defaultdict(list)\n",
    "\n",
    "horz_pf_interp = interp1d(space, horz_pf, bounds_error=False, fill_value=[0])\n",
    "ama_pf_interp = interp1d(space, ama_pf, bounds_error=False, fill_value=[0])\n",
    "\n",
    "def rf_model(width, mean, ama_pos, horz_pos, horz_weight, center_weight):\n",
    "    horz_weight = sigmoid(horz_weight)\n",
    "    center_weight = sigmoid(center_weight)\n",
    "\n",
    "    center = gaussian(x=space, sigma=abs(width), mu=mean)\n",
    "    center /= -np.sum(center) # make center unit vector like horz_pf and ama_pf\n",
    "\n",
    "    new_ama_space = np.linspace(np.min(space)-ama_pos, np.max(space)-ama_pos, len(space))\n",
    "    new_horz_space = np.linspace(np.min(space)-horz_pos, np.max(space)-horz_pos, len(space))\n",
    "    ama = ama_pf_interp(new_ama_space)/np.sum(ama_pf_interp(new_ama_space))\n",
    "    horz = horz_pf_interp(new_horz_space)/np.sum(horz_pf_interp(new_horz_space))\n",
    "\n",
    "    return center_weight*center + (1-center_weight)*(horz_weight*horz + (1-horz_weight)*ama)\n",
    "\n",
    "for celltype in receptive_fields.keys():\n",
    "    if celltype in ['ganglion', 'fast_on', 'fast_off_adapting', 'fast_off_sensitizing', \n",
    "                    'medium_off_adapting', 'slow_off']: \n",
    "                \n",
    "        popts = []\n",
    "        params = []\n",
    "        \n",
    "#         print('Fitting ganglion celltype %s.' %celltype)\n",
    "        for i,rf in tqdm(enumerate(receptive_fields[celltype])):\n",
    "            \n",
    "            def model_error_to_ganglion_cells(weights):\n",
    "                width, mean, ama_pos, horz_pos, hw, cw = weights\n",
    "                modeled_rf = rf_model(width, mean, ama_pos, horz_pos, hw, cw)\n",
    "                normed_rf = np.max(abs(rf))*modeled_rf/np.max(abs(modeled_rf))\n",
    "                # add regularization to ama_pos and horz_pos\n",
    "                return sum(abs(normed_rf - rf)**2) #+ 0.005*(ama_pos**2 + horz_pos**2)\n",
    "\n",
    "            best_fit_err = np.inf\n",
    "            for itr in range(iterations):\n",
    "                # center width\n",
    "                # center position\n",
    "                # ama position\n",
    "                # horz position\n",
    "                # horz/ama weight\n",
    "                # center/surr weight\n",
    "                this_popt = minimize(model_error_to_ganglion_cells, np.hstack([center_widths[celltype][i]+0.5*np.random.randn(1),\n",
    "                                                                               0.1*np.random.randn(3),\n",
    "                                                                               np.random.randn(2)]),\n",
    "                                    method='L-BFGS-B',\n",
    "                                    bounds=[(1e-6,None), (np.min(space),np.max(space)), (np.min(space),np.max(space)),\n",
    "                                           (np.min(space),np.max(space)), (None,None), (None,None)])\n",
    "                if this_popt.fun < best_fit_err:\n",
    "                    best_fit_err = this_popt.fun\n",
    "                    popt = this_popt\n",
    "            \n",
    "            # get mean squared error\n",
    "            modeled_rf = rf_model(*popt.x)\n",
    "            normed_rf = np.max(abs(rf))*modeled_rf/np.max(abs(modeled_rf))\n",
    "            mse = np.mean((normed_rf - rf)**2)\n",
    "\n",
    "            # translate hw and cw params back into [0,1] range\n",
    "            x = sigmoid(popt.x[-2:])\n",
    "\n",
    "            popts.append(x)\n",
    "            params.append(popt.x)\n",
    "            abs_errors[celltype].append(popt.fun)\n",
    "            mean_squared_errors[celltype].append(mse)\n",
    "            variances[celltype].append(np.var(rf))\n",
    "\n",
    "        fits[celltype] = np.stack(popts)\n",
    "        all_params[celltype] = np.stack(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "global_celltype = 'medium_off_adapting' #'fast_off_adapting'\n",
    "point_size = 7 #10\n",
    "min_info = np.min(info_maps[global_celltype])\n",
    "max_info = np.max(info_maps[global_celltype])\n",
    "empirical_ideal_indices = np.unravel_index(np.argmax(info_maps[global_celltype]), info_maps[global_celltype].shape)\n",
    "empirical_ideal = [horz_weights[empirical_ideal_indices[0]], center_weights[empirical_ideal_indices[1]]]\n",
    "\n",
    "########## for quivers #########\n",
    "all_fits = []\n",
    "for celltype in fits.keys():\n",
    "    all_fits.extend(fits[celltype])\n",
    "    \n",
    "pca = PCA(n_components=2)\n",
    "pca.fit(all_fits)\n",
    "\n",
    "# flipping the dimensions because fits was saved as horz_weight, center_weight\n",
    "average_variance_direction = abs(np.array([pca.components_[0][1], pca.components_[0][0]]))\n",
    "print('PC1 has explained variance %0.2f%% percent for all cells' %(pca.explained_variance_ratio_[0]*100))\n",
    "\n",
    "max_info_coordinates = collections.defaultdict(list)\n",
    "least_info_directions = collections.defaultdict(list)\n",
    "for celltype in info_maps.keys():\n",
    "    for x in range(info_maps[celltype].shape[0]):\n",
    "        for y in range(info_maps[celltype].shape[1]):\n",
    "            # take cloud of high efficiency points\n",
    "            if info_maps[celltype][x,y] >= 0.97*max_info:\n",
    "                max_info_coordinates[celltype].append([horz_weights[x], center_weights[y]])\n",
    "    pca = PCA()\n",
    "    pca.fit(max_info_coordinates[celltype])\n",
    "    print('PC1 has explained variance %0.2f%% percent for %s' %(pca.explained_variance_ratio_[0]*100, celltype))\n",
    "    least_info_directions[celltype] = abs(pca.components_[-1])\n",
    "    \n",
    "average_least_info_direction = np.mean([least_info_directions[k] for k in least_info_directions.keys()], axis=0)\n",
    "############ end quivers ###########\n",
    "\n",
    "plt.imshow(info_maps[global_celltype], extent=(center_weights[0], center_weights[-1], horz_weights[-1], horz_weights[0]),\n",
    "              aspect='auto', clim=[min_info, max_info])\n",
    "cbar = plt.colorbar()\n",
    "cbar.set_ticks([6,7,8,9])\n",
    "# plt.clim(0,np.max(info_color_map))\n",
    "cbar.ax.set_ylabel('Mutual information (bits)', fontsize=18)\n",
    "\n",
    "for idc, celltype in enumerate([k for k in info_maps.keys() if k != 'ganglion']):\n",
    "    # make the points lying on the edges more visible\n",
    "    adjusted_fits1 = np.where(fits[celltype] == 1, 0.995, fits[celltype])\n",
    "    adjusted_fits = np.where(adjusted_fits1 < 0.001, 0.005, adjusted_fits1)\n",
    "    plt.scatter(adjusted_fits[:,1], adjusted_fits[:,0],\n",
    "                c=colorscheme[celltype], edgecolor='w', s=point_size, alpha=0.5, label=' '.join(celltype.split('_')),\n",
    "                linewidth=0.3)\n",
    "#     plt.scatter(adjusted_fits[example_ids[celltype]][:nexamples_for_this_plot,1],\n",
    "#                adjusted_fits[example_ids[celltype]][:nexamples_for_this_plot,0],\n",
    "#                c=colorscheme[celltype], edgecolor='k', s=60, marker='*', linewidth=0.7)\n",
    "\n",
    "\n",
    "# plt.quiver(ideal_fit[1], ideal_fit[0], average_variance_direction[0], average_variance_direction[1],\n",
    "#            angles='xy', scale_units='xy', scale=2.5, color='k', edgecolor='w', width=0.012, linewidth=1,\n",
    "#           alpha=0.9)\n",
    "# plt.quiver(ideal_fit[1], ideal_fit[0], average_least_info_direction[0], average_least_info_direction[1],\n",
    "#            angles='xy', scale_units='xy', scale=2.5, color='w', edgecolor='k',\n",
    "#           alpha=0.7, width=.012, linewidth=1.2)\n",
    "# plt.scatter(ideal_fit[1], ideal_fit[0], c='k', edgecolor='k', s=150, marker='*', linewidth=0.7)\n",
    "\n",
    "plt.quiver(empirical_ideal[1], empirical_ideal[0], average_variance_direction[0], average_variance_direction[1],\n",
    "           angles='xy', scale_units='xy', scale=2.5, color='k', edgecolor='w', width=0.012, linewidth=1,\n",
    "          alpha=0.9)\n",
    "plt.quiver(empirical_ideal[1], empirical_ideal[0], average_least_info_direction[0], average_least_info_direction[1],\n",
    "           angles='xy', scale_units='xy', scale=2.5, color='w', edgecolor='k',\n",
    "          alpha=0.7, width=.012, linewidth=1.2)\n",
    "plt.scatter(empirical_ideal[1], empirical_ideal[0], c='k', edgecolor='k', s=150, marker='*', linewidth=0.7)\n",
    "\n",
    "\n",
    "# l = plt.legend(loc='upper left', frameon=False, fontsize=8)\n",
    "# for text in l.get_texts():\n",
    "#     text.set_color(\"white\")\n",
    "plt.ylim([0,1])\n",
    "plt.xlim([center_weights[0], center_weights[-1]])\n",
    "\n",
    "\n",
    "# specify ticks\n",
    "# plt.xticks([0, 0.25, 0.5, 0.75, 1])\n",
    "# plt.yticks([0, 0.25, 0.5, 0.75, 1])\n",
    "majorLocator = MultipleLocator(0.5)\n",
    "majorFormatter = FormatStrFormatter('%0.1f')\n",
    "minorLocator = MultipleLocator(0.25)\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.xaxis.set_major_locator(majorLocator)\n",
    "ax.xaxis.set_major_formatter(majorFormatter)\n",
    "ax.xaxis.set_minor_locator(minorLocator)\n",
    "ax.yaxis.set_major_locator(majorLocator)\n",
    "ax.yaxis.set_major_formatter(majorFormatter)\n",
    "ax.yaxis.set_minor_locator(minorLocator)\n",
    "\n",
    "# plt.title('Total information of various models \\n with fitted ganglion cells', fontsize=16)\n",
    "plt.xlabel('Center (1 - Surround) Weight', fontsize=16)\n",
    "plt.ylabel('Horizontal (1 - Amacrine) Weight', fontsize=16)\n",
    "ax.xaxis.set_ticks_position('bottom')\n",
    "ax.yaxis.set_ticks_position('left')\n",
    "# #plt.savefig('Figures for Steve IV.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "empirical_ideal_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "empirical_ideal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Quality of fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "bins = np.linspace(0,1,50)\n",
    "bin_width = np.mean(np.diff(bins))\n",
    "prev_count = np.zeros_like(bins[:-1])\n",
    "\n",
    "ax = plt.gca()\n",
    "\n",
    "for i,celltype in enumerate(mean_squared_errors.keys()):\n",
    "    if 'ganglion' != celltype:\n",
    "        rel_error = np.array(mean_squared_errors[celltype])/np.array(variances[celltype])\n",
    "        ax.vlines(np.median(rel_error), 0, 600, color=colorscheme[celltype], linestyle='--', alpha=0.8, zorder=i)\n",
    "\n",
    "    \n",
    "plt.xlabel('Relative error (normalized by filter variance)')\n",
    "plt.ylabel('Cell count')\n",
    "# ax = plt.gca()\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.yaxis.set_ticks_position('left')\n",
    "ax.xaxis.set_ticks_position('bottom')\n",
    "plt.ylim(0,600)\n",
    "\n",
    "for j,celltype in enumerate(mean_squared_errors.keys()):\n",
    "    if 'ganglion' != celltype:\n",
    "        rel_error = np.array(mean_squared_errors[celltype])/np.array(variances[celltype])\n",
    "        count, bins = np.histogram(rel_error, bins=bins)\n",
    "\n",
    "#         plt.bar(bins[:-1]+bin_width/2, count, width=bin_width, color=colorscheme[celltype], \n",
    "#                 label=' '.join(celltype.split('_')), edgecolor='k', bottom=prev_count, zorder=j+10)\n",
    "\n",
    "        plt.bar(bins[:-1]+bin_width/2, count, width=bin_width, color=colorscheme[celltype], \n",
    "                label=' '.join(celltype.split('_')), bottom=prev_count, zorder=j+10)\n",
    "\n",
    "#         plt.bar(bins[:-1]+bin_width/2, count, width=bin_width, color=colorscheme[celltype], \n",
    "#                 label=' '.join(celltype.split('_')), alpha=0.9, zorder=j+10)\n",
    "        prev_count += count\n",
    "\n",
    "\n",
    "plt.legend(loc='upper right', frameon=False, fontsize=9)\n",
    "# #plt.savefig('2017-3-29 Percent variance explained by model with median.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "rel_errors = []\n",
    "for j,celltype in enumerate(mean_squared_errors.keys()):\n",
    "    if 'ganglion' != celltype:\n",
    "        rel_errors.extend(np.array(mean_squared_errors[celltype])/np.array(variances[celltype]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print(len(rel_errors))\n",
    "100.*(1. - np.mean(rel_errors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sem(100.*(1. - np.array(rel_errors)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Correlate the quality of fit with the horz/amacrine fit and the center/surround fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "ax1 = plt.subplot(1,2,1)\n",
    "ax2 = plt.subplot(1,2,2)\n",
    "relative_errors = collections.defaultdict(list)\n",
    "\n",
    "hw_bins = np.linspace(0,1,10)\n",
    "cw_bins = np.linspace(0,1,10)\n",
    "\n",
    "for celltype in mean_squared_errors.keys():\n",
    "    rel_error = np.array(mean_squared_errors[celltype])/np.array(variances[celltype])\n",
    "    relative_errors[celltype] = rel_error\n",
    "    \n",
    "    hw_binned_rel_error = [[err for ide,err in enumerate(rel_error) if np.argmin((fits[celltype][ide,0] - hw_bins)**2) == idb] for idb in range(len(hw_bins))]\n",
    "    cw_binned_rel_error = [[err for ide,err in enumerate(rel_error) if np.argmin((fits[celltype][ide,1] - cw_bins)**2) == idb] for idb in range(len(cw_bins))]\n",
    "    avg_hw_rel_error = [np.mean(r) for r in hw_binned_rel_error]\n",
    "    avg_cw_rel_error = [np.mean(r) for r in cw_binned_rel_error]\n",
    "    \n",
    "    # Horizontal weight\n",
    "    ax1.bar(hw_bins, avg_hw_rel_error, width=np.mean(np.diff(hw_bins)), color=colorscheme[celltype],\n",
    "               label=' '.join(celltype.split('_')), alpha=0.8)\n",
    "    ax1.set_ylabel('Relative Error')\n",
    "    ax1.set_xlabel('Horizontal weight')\n",
    "    ax1.set_title('Horizontal weight')\n",
    "    \n",
    "    ax2.bar(cw_bins, avg_cw_rel_error, width=np.mean(np.diff(cw_bins)), color=colorscheme[celltype],\n",
    "               label=' '.join(celltype.split('_')), alpha=0.8)\n",
    "    ax2.set_ylabel('Relative Error')\n",
    "    ax2.set_xlabel('Center weight')\n",
    "    ax2.set_title('Center weight')\n",
    "\n",
    "#ax = plt.gca()\n",
    "ax1.spines['right'].set_visible(False)\n",
    "ax1.spines['top'].set_visible(False)\n",
    "ax1.yaxis.set_ticks_position('left')\n",
    "ax1.xaxis.set_ticks_position('bottom')\n",
    "\n",
    "ax2.spines['right'].set_visible(False)\n",
    "ax2.spines['top'].set_visible(False)\n",
    "ax2.yaxis.set_ticks_position('left')\n",
    "ax2.xaxis.set_ticks_position('bottom')\n",
    "                  \n",
    "# plt.ylim(0,200)\n",
    "# #plt.savefig('Percent variance explained by model with median.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "error_threshold = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "total_number_remaining = 0\n",
    "total_number_before = 0\n",
    "for celltype in fits.keys():\n",
    "    good_fits = float(fits[celltype][relative_errors[celltype] < error_threshold].shape[0])\n",
    "    all_fits = float(fits[celltype].shape[0])\n",
    "    print('%f%% of %s' %(100.*good_fits/all_fits, celltype))\n",
    "    \n",
    "    total_number_remaining += good_fits\n",
    "    total_number_before += all_fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "1.0*total_number_remaining/total_number_before"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Mapping ideal fit to our parameter space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "global_celltype = 'fast_off_adapting'\n",
    "iterations = 50\n",
    "\n",
    "rf = -np.fft.fftshift(np.fft.irfft(ideal_filter))\n",
    "rf = np.append(rf, rf[-1])\n",
    "\n",
    "center = gaussian(x=space, sigma=median_center_widths[global_celltype], mu=0.)\n",
    "center /= -np.sum(center) # make center unit vector like horz_pf and ama_pf\n",
    "\n",
    "def rf_model(horz_weight, center_weight):\n",
    "    horz_weight = np.min([1.0, abs(horz_weight)])\n",
    "    center_weight = np.min([1.0, abs(center_weight)])\n",
    "    return center_weight*center + (1-center_weight)*(horz_weight*horz_pf + (1-horz_weight)*ama_pf)\n",
    "\n",
    "def model_error_to_ganglion_cells(weights):\n",
    "    hw, cw = weights\n",
    "    modeled_rf = rf_model(hw, cw)\n",
    "    normed_rf = np.max(abs(rf))*modeled_rf/np.max(abs(modeled_rf))\n",
    "    return sum(abs(normed_rf - rf))\n",
    "\n",
    "best_fit_err = np.inf\n",
    "for itr in range(iterations):\n",
    "    this_popt = minimize(model_error_to_ganglion_cells, np.random.rand(2))\n",
    "    if this_popt.fun < best_fit_err:\n",
    "        best_fit_err = this_popt.fun\n",
    "        popt = this_popt\n",
    "\n",
    "# get mean squared error\n",
    "modeled_rf = rf_model(*popt.x)\n",
    "normed_rf = np.max(abs(rf))*modeled_rf/np.max(abs(modeled_rf))\n",
    "mse = np.mean((normed_rf - rf)**2)\n",
    "\n",
    "# truncate params between 0 and 1\n",
    "#             x = np.where(popt.x < 0, 0, popt.x) # this actually is wrong, since I'm abs(params) in rf_model\n",
    "#             x = np.where(x > 1, 1, x)\n",
    "x = np.where(abs(popt.x) > 1, 1, abs(popt.x))\n",
    "ideal_fit = x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Pick examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "fits[celltype][10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "center_weights[np.argmax(np.max(info_maps[celltype], axis=0))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "nexamples = 10\n",
    "example_rfs = collections.defaultdict(list)\n",
    "example_ids = collections.defaultdict(list)\n",
    "example_cws = collections.defaultdict(list)\n",
    "\n",
    "for celltype in receptive_fields.keys():\n",
    "    if celltype in ['ganglion', 'fast_on', 'fast_off_adapting', 'fast_off_sensitizing', \n",
    "                    'medium_off_adapting', 'slow_off']: \n",
    "        \n",
    "        rf_ids = np.arange(len(receptive_fields[celltype]))\n",
    "        schedule = np.random.permutation(rf_ids)\n",
    "                \n",
    "        for i in schedule:\n",
    "            rf = receptive_fields[celltype][i]\n",
    "#         for i,rf in enumerate(receptive_fields[celltype]):\n",
    "            x = fits[celltype][i]\n",
    "                        \n",
    "            # collect examples\n",
    "            if len(example_rfs[celltype]) <= nexamples:\n",
    "                # check if the fit is close to the optimimum center weight\n",
    "                if abs(x[1] - center_weights[np.argmax(np.max(info_maps[celltype], axis=0))]) < 0.015:\n",
    "                    example_rfs[celltype].append(rf)\n",
    "                    example_ids[celltype].append(i)\n",
    "                    example_cws[celltype].append(x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "nexamples_for_this_plot = 10\n",
    "# celltype = 'fast_off_adapting'\n",
    "for ide in range(nexamples_for_this_plot):\n",
    "    for celltype in example_rfs.keys():\n",
    "        if len(example_rfs[celltype]) > ide and celltype != 'ganglion':\n",
    "            ex = example_rfs[celltype][ide]\n",
    "            if ide == 0:\n",
    "                plt.plot(space, ex/np.max(abs(ex)), alpha=1-ide/nexamples_for_this_plot, \n",
    "                         color=colorscheme[celltype], label=' '.join(celltype.split('_')))\n",
    "            else:\n",
    "                plt.plot(space, ex/np.max(abs(ex)), color=colorscheme[celltype])\n",
    "            \n",
    "plt.ylim(-1.1, 0.4)\n",
    "plt.xlabel('Space (degrees)')\n",
    "plt.ylabel('Normalized sensitivity')\n",
    "plt.title('Diversity of receptive field model fits')\n",
    "plt.legend(loc='lower left', frameon=False, fontsize=9)\n",
    "adjust_spines(plt.gca())\n",
    "# #plt.savefig('diversity of receptive fields in space peak with constrained noise rerun 3-27.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# celltype = 'fast_off_adapting'\n",
    "for ide in range(nexamples_for_this_plot):\n",
    "    for celltype in example_rfs.keys():\n",
    "        if len(example_rfs[celltype]) > ide and celltype != 'ganglion':\n",
    "            ex = example_rfs[celltype][ide]\n",
    "            ex_fft = abs(np.fft.rfft(ex))\n",
    "            if ide == 0:\n",
    "                plt.plot(freqs, ex_fft/np.max(abs(ex_fft)), alpha=1-ide/nexamples_for_this_plot, \n",
    "                         color=colorscheme[celltype], label=' '.join(celltype.split('_')), linewidth=2)\n",
    "            else:\n",
    "                plt.plot(freqs, ex_fft/np.max(abs(ex_fft)),\n",
    "                         color=colorscheme[celltype], linewidth=2)\n",
    "            \n",
    "plt.ylim(-0.1, 1.3)\n",
    "plt.xlim(0.0124, 1.2)\n",
    "plt.xscale('log')\n",
    "plt.xlabel('Spatial frequency (degrees$^{-1}$)')\n",
    "plt.ylabel('Normalized amplitude')\n",
    "plt.title('Diversity of receptive fields')\n",
    "plt.legend(loc='upper right', frameon=False, fontsize=9)\n",
    "adjust_spines(plt.gca())\n",
    "# #plt.savefig('diversity of receptive fields in freq logscale peak with constrained noise rerun 1-21.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "example_cws[celltype]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "fits[celltype][example_ids[celltype]][:nexamples_for_this_plot,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "global_celltype = 'medium_off_adapting' #'fast_off_adapting'\n",
    "point_size = 7 #10\n",
    "min_info = np.min(info_maps[global_celltype])\n",
    "max_info = np.max(info_maps[global_celltype])\n",
    "empirical_ideal_indices = np.unravel_index(np.argmax(info_maps[global_celltype]), info_maps[global_celltype].shape)\n",
    "empirical_ideal = [horz_weights[empirical_ideal_indices[0]], center_weights[empirical_ideal_indices[1]]]\n",
    "\n",
    "########## for quivers #########\n",
    "all_fits = []\n",
    "# variance_directions = {}\n",
    "for celltype in fits.keys():\n",
    "    all_fits.extend(fits[celltype][relative_errors[celltype] < error_threshold])\n",
    "#     pca = PCA(n_components=2)\n",
    "#     pca.fit(fits[celltype][relative_errors[celltype] < error_threshold])\n",
    "\n",
    "#     # flipping the dimensions because fits was saved as horz_weight, center_weight\n",
    "#     variance_directions[celltype] = abs(np.array([pca.components_[0][1], pca.components_[0][0]]))\n",
    "#     print('PC1 has explained variance %0.2f%% percent for %s' %(pca.explained_variance_ratio_[0]*100, celltype))\n",
    "\n",
    "# average_variance_direction = np.mean(np.stack([variance_directions[k] for k in variance_directions.keys()]), axis=0)\n",
    "    \n",
    "pca = PCA(n_components=2)\n",
    "pca.fit(all_fits)\n",
    "\n",
    "# flipping the dimensions because fits was saved as horz_weight, center_weight\n",
    "average_variance_direction = abs(np.array([pca.components_[0][1], pca.components_[0][0]]))\n",
    "print('PC1 has explained variance %0.2f%% percent for all cells' %(pca.explained_variance_ratio_[0]*100))\n",
    "\n",
    "max_info_coordinates = collections.defaultdict(list)\n",
    "least_info_directions = collections.defaultdict(list)\n",
    "# celltype = global_celltype\n",
    "for celltype in info_maps.keys():\n",
    "    for x in range(info_maps[celltype].shape[0]):\n",
    "        for y in range(info_maps[celltype].shape[1]):\n",
    "            # take cloud of high efficiency points\n",
    "            if info_maps[celltype][x,y] >= 0.97*max_info:\n",
    "                max_info_coordinates[celltype].append([horz_weights[x], center_weights[y]])\n",
    "    pca = PCA()\n",
    "    pca.fit(max_info_coordinates[celltype])\n",
    "    print('PC1 has explained variance %0.2f%% percent for %s' %(pca.explained_variance_ratio_[0]*100, celltype))\n",
    "    least_info_directions[celltype] = abs(pca.components_[-1])\n",
    "    \n",
    "average_least_info_direction = np.mean([least_info_directions[k] for k in least_info_directions.keys()], axis=0)\n",
    "\n",
    "angle_diff = np.arctan(average_least_info_direction[1]/average_least_info_direction[0]) - np.arctan(average_variance_direction[1]/average_variance_direction[0])\n",
    "print('Angle difference in radians is %0.4f' %angle_diff)\n",
    "angle_diff_degs = (360./(2*np.pi))*angle_diff\n",
    "print('Angle difference in degrees is %0.4f' %angle_diff_degs)\n",
    "############ end quivers ###########\n",
    "\n",
    "plt.imshow(info_maps[global_celltype], extent=(center_weights[0], center_weights[-1], horz_weights[-1], horz_weights[0]),\n",
    "              aspect='auto', clim=[min_info, max_info])\n",
    "cbar = plt.colorbar()\n",
    "cbar.set_ticks([6,7,8,9])\n",
    "# plt.clim(0,np.max(info_color_map))\n",
    "cbar.ax.set_ylabel('Mutual information (bits)', fontsize=18)\n",
    "\n",
    "for idc, celltype in enumerate([k for k in info_maps.keys() if k != 'ganglion']):\n",
    "    # make the points lying on the edges more visible\n",
    "    adjusted_fits1 = np.where(fits[celltype] == 1, 0.995, fits[celltype])[relative_errors[celltype] < error_threshold]\n",
    "    adjusted_fits = np.where(adjusted_fits1 < 0.001, 0.005, adjusted_fits1)\n",
    "    plt.scatter(adjusted_fits[:,1], adjusted_fits[:,0],\n",
    "                c=colorscheme[celltype], edgecolor='w', s=point_size, alpha=0.5, label=' '.join(celltype.split('_')),\n",
    "                linewidth=0.3)\n",
    "    plt.scatter(fits[celltype][example_ids[celltype]][:nexamples_for_this_plot,1],\n",
    "               fits[celltype][example_ids[celltype]][:nexamples_for_this_plot,0],\n",
    "               c=colorscheme[celltype], edgecolor='k', s=60, marker='*', linewidth=0.7)\n",
    "\n",
    "\n",
    "# plt.quiver(ideal_fit[1], ideal_fit[0], average_variance_direction[0], average_variance_direction[1],\n",
    "#            angles='xy', scale_units='xy', scale=2.5, color='k', edgecolor='w', width=0.012, linewidth=1,\n",
    "#           alpha=0.9)\n",
    "# plt.quiver(ideal_fit[1], ideal_fit[0], average_least_info_direction[0], average_least_info_direction[1],\n",
    "#            angles='xy', scale_units='xy', scale=2.5, color='w', edgecolor='k',\n",
    "#           alpha=0.7, width=.012, linewidth=1.2)\n",
    "# plt.scatter(ideal_fit[1], ideal_fit[0], c='k', edgecolor='k', s=150, marker='*', linewidth=0.7)\n",
    "\n",
    "plt.quiver(empirical_ideal[1], empirical_ideal[0], average_variance_direction[0], average_variance_direction[1],\n",
    "           angles='xy', scale_units='xy', scale=2.5, color='k', edgecolor='w', width=0.012, linewidth=1,\n",
    "          alpha=0.9)\n",
    "plt.quiver(empirical_ideal[1], empirical_ideal[0], average_least_info_direction[0], average_least_info_direction[1],\n",
    "           angles='xy', scale_units='xy', scale=2.5, color='w', edgecolor='k',\n",
    "          alpha=0.7, width=.012, linewidth=1.2)\n",
    "plt.scatter(empirical_ideal[1], empirical_ideal[0], c='k', edgecolor='k', s=150, marker='*', linewidth=0.7)\n",
    "\n",
    "\n",
    "# l = plt.legend(loc='upper left', frameon=False, fontsize=8)\n",
    "# for text in l.get_texts():\n",
    "#     text.set_color(\"white\")\n",
    "plt.ylim([0,1])\n",
    "plt.xlim([center_weights[0], center_weights[-1]])\n",
    "\n",
    "\n",
    "# specify ticks\n",
    "# plt.xticks([0, 0.25, 0.5, 0.75, 1])\n",
    "# plt.yticks([0, 0.25, 0.5, 0.75, 1])\n",
    "majorLocator = MultipleLocator(0.5)\n",
    "majorFormatter = FormatStrFormatter('%0.1f')\n",
    "minorLocator = MultipleLocator(0.25)\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.xaxis.set_major_locator(majorLocator)\n",
    "ax.xaxis.set_major_formatter(majorFormatter)\n",
    "ax.xaxis.set_minor_locator(minorLocator)\n",
    "ax.yaxis.set_major_locator(majorLocator)\n",
    "ax.yaxis.set_major_formatter(majorFormatter)\n",
    "ax.yaxis.set_minor_locator(minorLocator)\n",
    "\n",
    "# plt.title('Total information of various models \\n with fitted ganglion cells', fontsize=16)\n",
    "plt.xlabel('Center (1 - Surround) Weight', fontsize=16)\n",
    "plt.ylabel('Horizontal (1 - Amacrine) Weight', fontsize=16)\n",
    "ax.xaxis.set_ticks_position('bottom')\n",
    "ax.yaxis.set_ticks_position('left')\n",
    "# #plt.savefig('2017 3-27 Fig3D information map')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "angle_diff = np.arctan(average_least_info_direction[1]/average_least_info_direction[0]) - np.arctan(average_variance_direction[1]/average_variance_direction[0])\n",
    "print('Angle difference in radians is %0.4f' %angle_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "angle_diff_degs = (360./(2*np.pi))*angle_diff\n",
    "print('Angle difference in degrees is %0.4f' %angle_diff_degs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "fig = plt.gcf()\n",
    "ax = plt.gca()\n",
    "\n",
    "# Histogram\n",
    "bin_edges = np.linspace(0, 1, 30)\n",
    "bin_width = np.mean(np.diff(bin_edges))\n",
    "prev_count = np.zeros_like(bin_edges[:-1])\n",
    "# for c, celltype in enumerate(fits.keys()):\n",
    "for c, celltype in enumerate(['fast_off_adapting', 'medium_off_adapting', 'slow_off', 'fast_off_sensitizing', 'fast_on']):\n",
    "    if celltype != 'ganglion':\n",
    "        this_count, bins = np.histogram(fits[celltype][:, 0][relative_errors[celltype] < error_threshold],\n",
    "                                        bins=bin_edges)\n",
    "#         ax.bar(bin_edges[:-1] + bin_width/2, this_count, color=colorscheme[celltype], width=bin_width,\n",
    "#                bottom=prev_count, linewidth=0.5, label=' '.join(celltype.split(' ')), zorder=c+20)\n",
    "        ax.bar(bin_edges[:-1] + bin_width/2, this_count, color=colorscheme[celltype], width=bin_width,\n",
    "               bottom=prev_count, linewidth=0.5, label=' '.join(celltype.split(' ')), zorder=c+20)\n",
    "#         ax.bar(bin_edges[:-1] + bin_width/2, this_count, color=colorscheme[celltype], width=bin_width,\n",
    "#                linewidth=0.5, label=' '.join(celltype.split(' ')), alpha=0.9, zorder=c+20)\n",
    "\n",
    "        prev_count += this_count\n",
    "        \n",
    "        plt.vlines(np.median(fits[celltype][:, 0][relative_errors[celltype] < error_threshold]),\n",
    "                   0, 150, color=colorscheme[celltype], linestyle='--', alpha=0.8, zorder=c)\n",
    "        \n",
    "l = plt.legend(frameon=False, fontsize=9, loc='upper right')\n",
    "for text in l.get_texts():\n",
    "    splitlabel = text.properties()['text'].split(' ')\n",
    "    text.set_color(colorscheme['_'.join(splitlabel)])\n",
    "\n",
    "        \n",
    "\n",
    "plt.xlim(0,1.007)\n",
    "# plt.xticks([0, 0.25, 0.5, 0.75, 1])\n",
    "ax.set_ylabel('# Cells', color='k', fontsize=20)\n",
    "ax.set_xlabel('Horizontal (1 - Amacrine) Weight')\n",
    "# ax.set_ylim(0,140)\n",
    "# ax.set_yticks([0,100,200,300])\n",
    "\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.xaxis.set_ticks_position('bottom')\n",
    "ax.yaxis.set_ticks_position('left')\n",
    "ax.spines['bottom'].set_visible(False)\n",
    "\n",
    "# ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.xaxis.set_ticks_position('bottom')\n",
    "\n",
    "\n",
    "\n",
    "majorLocator = MultipleLocator(50)\n",
    "majorFormatter = FormatStrFormatter('%d')\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.yaxis.set_major_locator(majorLocator)\n",
    "ax.yaxis.set_major_formatter(majorFormatter)\n",
    "# ax.xaxis.set_minor_locator(minorLocator)\n",
    "\n",
    "# ax.yaxis.set_ticks_position('left')\n",
    "# adjust_spines(plt.gca())\n",
    "# plt.xlabel('Center (1 - surround) weight')\n",
    "# plt.ylabel('# Cells')\n",
    "# #plt.savefig('1d y-axis distribution 3-29.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# for c, celltype in enumerate(fits.keys()):\n",
    "for c, celltype in enumerate(['fast_off_sensitizing', 'slow_off', 'fast_on', 'fast_off_adapting',\n",
    "                             'medium_off_adapting']):\n",
    "    if celltype != 'ganglion':\n",
    "        plt.plot(center_weights, info_maps[celltype][75, :], alpha=0.8, color=colorscheme[celltype])\n",
    "        infos_at_horz_slice = []\n",
    "        center_weight_fits = np.stack(fits[celltype])[:, 1][relative_errors[celltype] < error_threshold]\n",
    "        for f in fits[celltype]:\n",
    "            idx = np.argmin(abs(f[0] - horz_weights))\n",
    "            idy = np.argmin(abs(f[1] - center_weights))\n",
    "            infos_at_horz_slice.append(info_maps[celltype][idx, idy])\n",
    "\n",
    "    #     color = np.random.rand(3)\n",
    "#         plt.scatter(center_weight_fits, infos_at_horz_slice, color=colorscheme[celltype], \n",
    "#                     label=' '.join(celltype.split('_')), s=30, edgecolor='w', lw=0.5)\n",
    "        plt.vlines(np.median(center_weight_fits), 0, 11, color=colorscheme[celltype], linestyle='--', alpha=0.8)\n",
    "    \n",
    "# l = plt.legend(frameon=False, fontsize=9, loc='upper left')\n",
    "# for text in l.get_texts():\n",
    "#     splitlabel = text.properties()['text'].split(' ')\n",
    "#     text.set_color(colorscheme['_'.join(splitlabel)])\n",
    "\n",
    "plt.ylabel('Information (bits)', fontsize=20)\n",
    "# adjust_spines(plt.gca())\n",
    "plt.ylim(0, 10)\n",
    "plt.xlim(0,1.1)\n",
    "ax1 = plt.gca()\n",
    "ax1.spines['right'].set_visible(False)\n",
    "ax1.spines['top'].set_visible(False)\n",
    "ax1.xaxis.set_ticks_position('bottom')\n",
    "ax1.yaxis.set_ticks_position('left')\n",
    "ax1.spines['bottom'].set_visible(False)\n",
    "plt.xticks([])\n",
    "ax1.set_xlabel('Center (1 - Surround) Weight', fontsize=20)\n",
    "\n",
    "majorLocator = MultipleLocator(0.5)\n",
    "majorFormatter = FormatStrFormatter('%0.1f')\n",
    "minorLocator = MultipleLocator(0.25)\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.xaxis.set_major_locator(majorLocator)\n",
    "ax.xaxis.set_major_formatter(majorFormatter)\n",
    "ax.xaxis.set_minor_locator(minorLocator)\n",
    "\n",
    "# Histogram\n",
    "bin_edges = np.linspace(0, 1, 50)\n",
    "bin_width = np.mean(np.diff(bin_edges))\n",
    "prev_count = np.zeros_like(bin_edges[:-1])\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "# for c, celltype in enumerate(fits.keys()):\n",
    "for c, celltype in enumerate(['fast_off_sensitizing', 'slow_off', 'fast_on', 'fast_off_adapting',\n",
    "                             'medium_off_adapting']):\n",
    "    if celltype != 'ganglion':\n",
    "        this_count, bins = np.histogram(np.stack(fits[celltype])[:, 1][relative_errors[celltype] < error_threshold],\n",
    "                                        bins=bin_edges)\n",
    "#         ax2.bar(bin_edges[:-1] + bin_width/2, this_count, color=colorscheme[celltype], width=bin_width,\n",
    "#                bottom=prev_count, linewidth=0.5, edgecolor='k')\n",
    "        ax2.bar(bin_edges[:-1] + bin_width/2, this_count, color=colorscheme[celltype], width=bin_width,\n",
    "               bottom=prev_count, linewidth=0.5)\n",
    "#         ax2.bar(bin_edges[:-1] + bin_width/2, this_count, color=colorscheme[celltype], width=bin_width,\n",
    "#                linewidth=0.5, alpha=0.85)\n",
    "\n",
    "        prev_count += this_count\n",
    "\n",
    "plt.xlim(0,1.007)\n",
    "# plt.xticks([0, 0.25, 0.5, 0.75, 1])\n",
    "ax2.set_ylabel('# Cells', color='k', fontsize=20)\n",
    "ax2.set_ylim(0,340)\n",
    "ax2.set_yticks([0,100,200,300])\n",
    "\n",
    "# ax.spines['right'].set_visible(False)\n",
    "ax2.spines['top'].set_visible(False)\n",
    "ax2.xaxis.set_ticks_position('bottom')\n",
    "\n",
    "# ax.yaxis.set_ticks_position('left')\n",
    "# adjust_spines(plt.gca())\n",
    "# plt.xlabel('Center (1 - surround) weight')\n",
    "# plt.ylabel('# Cells')\n",
    "# #plt.savefig('1d info slice with histogram with constrained noise rerun 3-29.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Fig 3A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "ffts = []\n",
    "for rf in receptive_fields['ganglion']:\n",
    "    this_fft = abs(np.fft.rfft(rf))\n",
    "    this_fft /= np.max(this_fft)\n",
    "    ffts.append(this_fft)\n",
    "\n",
    "# avg_rf = np.mean(receptive_fields['ganglion'], axis=0)\n",
    "# avg_rf_fft = abs(np.fft.rfft(avg_rf))\n",
    "# plt.plot(freqs, avg_rf_fft)\n",
    "\n",
    "sems = sem(np.stack(ffts))\n",
    "stds = np.std(np.stack(ffts), axis=0)\n",
    "avg_rf_fft = abs(np.mean(np.stack(ffts), axis=0))\n",
    "avg_rf_fft2 = np.mean(abs(np.stack(ffts)), axis=0)\n",
    "\n",
    "plt.errorbar(freqs, avg_rf_fft/np.max(avg_rf_fft), yerr=sems/np.max(avg_rf_fft), color='g')\n",
    "plt.errorbar(freqs, avg_rf_fft2/np.max(avg_rf_fft2), yerr=sems/np.max(avg_rf_fft2), color='c')\n",
    "# plt.errorbar(freqs, avg_rf_fft2/np.max(avg_rf_fft2), yerr=stds/np.max(avg_rf_fft2), color='y')\n",
    "plt.plot(freqs, ideal_filter/np.max(ideal_filter), color='k')\n",
    "plt.plot(freqs, signal/np.max(signal), 'r')\n",
    "plt.xlim(0, 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Figures 3F & G"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Compute info while varying surround widths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "widths = np.linspace(0.01, 17, 100)\n",
    "init_filt_const = 10.9\n",
    "resolution = 100\n",
    "horz_weights = np.linspace(0,1,resolution)\n",
    "center_weights = np.linspace(0,1,resolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "infos_varying_width = collections.defaultdict(list)\n",
    "celltype = 'fast_off_adapting'\n",
    "with h5py.File('infos_varying_width.h5', 'r') as f:\n",
    "    tmp = dict(f)\n",
    "    width_tuples = list(tmp.keys())\n",
    "    for k in width_tuples:\n",
    "        lhs, rhs = k.split(',')\n",
    "        w1 = float(lhs.split('(')[1])\n",
    "        w2 = float(rhs.split(')')[0])\n",
    "        infos_varying_width[(w1, w2)] = np.array(f[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "max_info_vs_width = np.zeros((len(widths), len(widths)))\n",
    "for idw1,w1 in enumerate(widths):\n",
    "    for idw2,w2 in enumerate(widths[idw1:]):\n",
    "        max_info_vs_width[idw1, idw2+idw1] = np.max(infos_varying_width[(w1,w2)])\n",
    "        max_info_vs_width[idw2+idw1, idw1] = np.max(infos_varying_width[(w1,w2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "popt_horz, pcov = curve_fit(gaussian, space, horz_pf, p0=[2.5, 0.0, 2.1])\n",
    "popt_ama, pcov = curve_fit(gaussian, space, ama_pf, p0=[2.5, 0.0, 2.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "popt_horz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "popt_ama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "min_info = None\n",
    "max_info = None\n",
    "for idw1,w1 in enumerate(widths):\n",
    "    for idw2,w2 in enumerate(widths[idw1:]):\n",
    "        new_min = np.min(infos_varying_width[(w1,w2)])\n",
    "        new_max = np.max(infos_varying_width[(w1,w2)])\n",
    "        if (not min_info) or (min_info > new_min):\n",
    "            min_info = new_min\n",
    "        if (not max_info) or (max_info < new_max):\n",
    "            max_info = new_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "max_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "colorscheme = {\n",
    "    'ganglion': 'k',\n",
    "    'fast_off_sensitizing': 'r',\n",
    "    'fast_off_adapting': 'g',\n",
    "    'slow_off': 'y',\n",
    "    'fast_on': 'b',\n",
    "    'medium_off_adapting': 'c'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Data part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "data_dir = os.path.expanduser('~/data/kastner/')\n",
    "h_file = 'horizontals.h5'\n",
    "a_file = 'amacrines.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "interneuron_rfs = collections.defaultdict(list)\n",
    "with h5py.File(data_dir + h_file, 'r') as f:\n",
    "    keys = [str(k)[3:-2] for k in list(f['expts'])]\n",
    "    for ide,expt in tqdm(enumerate(keys)):\n",
    "        rf = np.array(f['lines/rfs/%s' %expt])\n",
    "        pca = PCA(n_components=2)\n",
    "        pca.fit(rf)\n",
    "        g_pca = pca.components_[0]\n",
    "\n",
    "        sign_of_pc = -1 * np.sign(g_pca[abs(g_pca) == np.max(abs(g_pca))])\n",
    "        interneuron_rfs['horizontal'].append(sign_of_pc * g_pca)\n",
    "\n",
    "with h5py.File(data_dir + a_file, 'r') as f:\n",
    "    keys = [str(k)[3:-2] for k in list(f['expts'])]\n",
    "    for ide,expt in tqdm(enumerate(keys)):\n",
    "        rf = np.array(f['lines/rfs/%s' %expt])\n",
    "        pca = PCA(n_components=2)\n",
    "        pca.fit(rf)\n",
    "        g_pca = pca.components_[0]\n",
    "\n",
    "        sign_of_pc = -1 * np.sign(g_pca[abs(g_pca) == np.max(abs(g_pca))])\n",
    "        interneuron_rfs['amacrine'].append(sign_of_pc * g_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "space_constant = {\n",
    "    'horizontal': 121./microns_per_degree, #118./microns_per_degree,\n",
    "    'amacrine': 102./microns_per_degree #78./microns_per_degree\n",
    "    }\n",
    "conv_mode = 'full'\n",
    "# spatial delta in mm * 1000) / microns_per_degree # microns * degrees/microns = degrees\n",
    "interneuron_spacing = (2.2/100.) # in mm\n",
    "\n",
    "interneuron_rfs_1d = collections.defaultdict(list)\n",
    "for interneuron_type in interneuron_rfs.keys():\n",
    "    for rf in interneuron_rfs[interneuron_type]:\n",
    "        this_space = get_space(rf, interneuron_spacing, microns_per_degree, in_degrees=True, kind='peak')\n",
    "        proj_range = [np.exp(-abs(t)/space_constant[interneuron_type]) for t in np.linspace(np.min(this_space),\n",
    "                                                                                    np.max(this_space),len(this_space))]\n",
    "        proj_field = np.convolve(proj_range, rf, mode=conv_mode)\n",
    "        proj_field *= np.mean(rf) / np.mean(proj_field)\n",
    "        \n",
    "        proj_space = get_space(proj_field, np.diff(this_space[:2]), microns_per_degree, in_degrees=False)\n",
    "        component_interp = interp1d(proj_space, proj_field, kind='slinear', bounds_error=False, fill_value=[0])\n",
    "        interneuron_rfs_1d[interneuron_type].append(component_interp(space))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "colorscheme = {\n",
    "    'horizontal': 'g',\n",
    "    'amacrine': 'b'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "interneuron_fits = collections.defaultdict(list)\n",
    "for interneuron_type in interneuron_rfs_1d.keys():\n",
    "    for component in interneuron_rfs_1d[interneuron_type]:\n",
    "        plt.plot(space, component/np.max(abs(component)), color=colorscheme[interneuron_type], alpha=0.5)\n",
    "\n",
    "plt.plot(space, -horz_pf/np.max(abs(horz_pf)), 'k', linewidth=8)\n",
    "plt.plot(space, -horz_pf/np.max(abs(horz_pf)), 'g')\n",
    "plt.plot(space, -ama_pf/np.max(abs(ama_pf)), 'k', linewidth=8)\n",
    "plt.plot(space, -ama_pf/np.max(abs(ama_pf)), 'b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "interneuron_fits = collections.defaultdict(list)\n",
    "for interneuron_type in interneuron_rfs_1d.keys():\n",
    "    for component in interneuron_rfs_1d[interneuron_type]:\n",
    "        popt, pcov = curve_fit(gaussian, space, -component, p0=[2.5, 0.0, 2.1])\n",
    "        interneuron_fits[interneuron_type].append(abs(popt[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "count_horz, horz_edges = np.histogram(interneuron_fits['horizontal'], bins=widths)\n",
    "count_ama, ama_edges = np.histogram(interneuron_fits['amacrine'], bins=widths)\n",
    "interneuron_pairs = np.outer(count_horz, count_ama)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def angle(rf1, rf2):\n",
    "    # an arccos(x > 1) returns nan. But we get some values x that are 1.0000000002 due to numerical imprecision\n",
    "    opp_hyp = np.min([1, np.inner(rf1, rf2)/(np.sqrt(np.sum(rf1**2)) * np.sqrt(np.sum(rf2**2)))])\n",
    "    a = np.arccos(opp_hyp)\n",
    "    return np.min([a, abs(a - 2*np.pi)])\n",
    "#     return np.arccos(np.inner(rf1, rf2)/(np.sqrt(np.sum(rf1**2)) * np.sqrt(np.sum(rf2**2))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "max_angles_fft = np.zeros((len(widths), len(widths)))\n",
    "max_angles_rf = np.zeros((len(widths), len(widths)))\n",
    "info_difference = np.zeros((len(widths), len(widths)))\n",
    "all_angles = []\n",
    "all_dots = []\n",
    "all_arccos = []\n",
    "all_info_losses = []\n",
    "\n",
    "center = gaussian(x=space, sigma=median_center_widths[celltype], mu=0.)\n",
    "center /= -np.sum(center)\n",
    "\n",
    "for idw1,w1 in enumerate(widths):\n",
    "    surround1 = gaussian(x=space, sigma=w1, mu=0.)\n",
    "    surround1 /= np.sum(surround1)\n",
    "    for idw2,w2 in enumerate(widths[idw1:]):\n",
    "#         print((w1,w2))\n",
    "        surround2 = gaussian(x=space, sigma=w2, mu=0.)\n",
    "        surround2 /= np.sum(surround2)\n",
    "\n",
    "        def rf_model(horz_weight, center_weight):\n",
    "            return center_weight*center + (1-center_weight)*(horz_weight*surround2 + (1-horz_weight)*surround1)\n",
    "\n",
    "        this_map = infos_varying_width[(w1,w2)]\n",
    "        which_fft = np.unravel_index(this_map.argmax(), this_map.shape)\n",
    "        hw = horz_weights[which_fft[0]]\n",
    "        cw = center_weights[which_fft[1]]\n",
    "        \n",
    "        rf = rf_model(hw, cw)\n",
    "        rf_filt = abs(np.fft.rfft(rf))\n",
    "        this_info = infos_varying_width[(w1,w2)][which_fft[0], which_fft[1]]\n",
    "        max_angle_fft = -1\n",
    "        max_angle_rf = -1\n",
    "        for idh,new_hw in enumerate(horz_weights):\n",
    "#             if w1 != w2:\n",
    "# #                 if new_hw != hw:\n",
    "#                 import pdb\n",
    "#                 pdb.set_trace()\n",
    "            \n",
    "            new_rf = rf_model(new_hw, cw)\n",
    "            new_filt = abs(np.fft.rfft(new_rf))\n",
    "            new_rf_angle = angle(rf, new_rf)\n",
    "            new_fft_angle = angle(rf_filt, new_filt)\n",
    "            \n",
    "            all_angles.append(new_rf_angle)\n",
    "            all_dots.append(np.inner(rf, new_rf)/(np.sqrt(np.sum(rf**2)) * np.sqrt(np.sum(new_rf**2))))\n",
    "            all_arccos.append(np.arccos(np.min([1,all_dots[-1]])))\n",
    "            all_info_losses.append(infos_varying_width[(w1,w2)][idh, which_fft[1]]/max_info)\n",
    "            \n",
    "            if new_rf_angle > max_angle_rf:\n",
    "                max_angle_rf = new_rf_angle\n",
    "            if new_fft_angle > max_angle_fft:\n",
    "                max_angle_fft = new_fft_angle\n",
    "                new_info = infos_varying_width[(w1,w2)][idh, which_fft[1]]\n",
    "#                 associated_info_diff = new_info/this_info\n",
    "                associated_info_diff = new_info/max_info\n",
    "                \n",
    "        max_angles_rf[idw1, idw2+idw1] = max_angle_rf\n",
    "        max_angles_rf[idw2+idw1, idw1] = max_angle_rf\n",
    "        max_angles_fft[idw1, idw2+idw1] = max_angle_fft\n",
    "        max_angles_fft[idw2+idw1, idw1] = max_angle_fft\n",
    "        info_difference[idw1, idw2+idw1] = associated_info_diff\n",
    "        info_difference[idw2+idw1, idw1] = associated_info_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "best_indices = []\n",
    "thresholds = np.linspace(0.01, 0.5, 20)\n",
    "for thresh in thresholds:\n",
    "    angles = max_angles_fft.ravel()\n",
    "    infos = info_difference.ravel()\n",
    "    local_max_info = 0\n",
    "    for i,a in enumerate(angles):\n",
    "        if a > thresh:\n",
    "            if infos[i] > local_max_info:\n",
    "                local_max_info = infos[i]\n",
    "                best_index = np.unravel_index(i, info_difference.shape)\n",
    "    best_indices.append(best_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "max_angles_fft_data = []\n",
    "max_angles_rf_data = []\n",
    "max_info_difference_data = []\n",
    "\n",
    "for h_width in interneuron_fits['horizontal']:\n",
    "    surround2 = gaussian(x=space, sigma=h_width, mu=0.)\n",
    "    surround2 /= np.sum(surround2)\n",
    "    \n",
    "    # choose the closest width in our lookup table\n",
    "    w2_idx = np.argmin(np.abs(h_width - widths))\n",
    "    w2 = widths[w2_idx]\n",
    "    \n",
    "    for a_width in interneuron_fits['amacrine']:\n",
    "        surround1 = gaussian(x=space, sigma=a_width, mu=0.)\n",
    "        surround1 /= np.sum(surround1)\n",
    "        \n",
    "        # choose the closest width in our lookup table\n",
    "        w1_idx = np.argmin(np.abs(a_width - widths))\n",
    "        w1 = widths[w1_idx]\n",
    "\n",
    "        def rf_model(horz_weight, center_weight):\n",
    "            return center_weight*center + (1-center_weight)*(horz_weight*surround2 + (1-horz_weight)*surround1)\n",
    "\n",
    "        if w1 > w2:\n",
    "            print('Triggered! %f, %f' %(h_width, a_width))\n",
    "            tmp = w1\n",
    "            w1 = w2\n",
    "            w2 = tmp\n",
    "            \n",
    "            def rf_model(horz_weight, center_weight):\n",
    "                return center_weight*center + (1-center_weight)*(horz_weight*surround1 + (1-horz_weight)*surround2)\n",
    "            \n",
    "        this_map = infos_varying_width[(w1,w2)]\n",
    "        which_fft = np.unravel_index(this_map.argmax(), this_map.shape)\n",
    "        hw = horz_weights[which_fft[0]]\n",
    "        cw = center_weights[which_fft[1]]\n",
    "        \n",
    "        rf = rf_model(hw, cw)\n",
    "        rf_filt = abs(np.fft.rfft(rf))\n",
    "        this_info = infos_varying_width[(w1,w2)][which_fft[0], which_fft[1]]\n",
    "        max_angle_fft = 0\n",
    "        max_angle_rf = 0\n",
    "        for idh,hw in enumerate(horz_weights):\n",
    "            new_rf = rf_model(hw, cw)\n",
    "            new_filt = abs(np.fft.rfft(new_rf))\n",
    "            new_rf_angle = angle(rf, new_rf)\n",
    "            new_fft_angle = angle(rf_filt, new_filt)\n",
    "            \n",
    "            if new_rf_angle > max_angle_rf:\n",
    "                max_angle_rf = new_rf_angle\n",
    "            if new_fft_angle > max_angle_fft:\n",
    "                max_angle_fft = new_fft_angle\n",
    "                new_info = infos_varying_width[(w1,w2)][idh, which_fft[1]]\n",
    "                associated_info_diff = new_info/this_info\n",
    "                \n",
    "        max_angles_rf_data.append(max_angle_rf)\n",
    "        max_angles_fft_data.append(max_angle_fft)\n",
    "        max_info_difference_data.append(associated_info_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "angles_fft_data = []\n",
    "angles_rf_data = []\n",
    "info_difference_data = []\n",
    "\n",
    "for h_width in interneuron_fits['horizontal']:\n",
    "    surround2 = gaussian(x=space, sigma=h_width, mu=0.)\n",
    "    surround2 /= np.sum(surround2)\n",
    "    \n",
    "    # choose the closest width in our lookup table\n",
    "    w2_idx = np.argmin(np.abs(h_width - widths))\n",
    "    w2 = widths[w2_idx]\n",
    "    \n",
    "#     surround2 = gaussian(x=space, sigma=w2, mu=0.)\n",
    "#     surround2 /= np.sum(surround2)\n",
    "    \n",
    "    for a_width in interneuron_fits['amacrine']:\n",
    "        surround1 = gaussian(x=space, sigma=a_width, mu=0.)\n",
    "        surround1 /= np.sum(surround1)\n",
    "        \n",
    "        # choose the closest width in our lookup table\n",
    "        w1_idx = np.argmin(np.abs(a_width - widths))\n",
    "        w1 = widths[w1_idx]\n",
    "        \n",
    "#         surround1 = gaussian(x=space, sigma=w1, mu=0.)\n",
    "#         surround1 /= np.sum(surround1)\n",
    "\n",
    "        def rf_model(horz_weight, center_weight):\n",
    "            return center_weight*center + (1-center_weight)*(horz_weight*surround2 + (1-horz_weight)*surround1)\n",
    "\n",
    "        if w1 > w2:\n",
    "            print('Triggered! %f, %f' %(h_width, a_width))\n",
    "            tmp = w1\n",
    "            w1 = w2\n",
    "            w2 = tmp\n",
    "            \n",
    "            def rf_model(horz_weight, center_weight):\n",
    "                return center_weight*center + (1-center_weight)*(horz_weight*surround1 + (1-horz_weight)*surround2)\n",
    "            \n",
    "        this_map = infos_varying_width[(w1,w2)]\n",
    "        which_fft = np.unravel_index(this_map.argmax(), this_map.shape)\n",
    "        hw = horz_weights[which_fft[0]]\n",
    "        cw = center_weights[which_fft[1]]\n",
    "        \n",
    "        mean_info = np.mean(infos_varying_width[(w1,w2)][:, which_fft[1]])\n",
    "\n",
    "        all_h_rf = rf_model(horz_weights[-1], cw)\n",
    "        all_a_rf = rf_model(horz_weights[0], cw)\n",
    "        \n",
    "        all_h_fft = abs(np.fft.rfft(all_h_rf))\n",
    "        all_a_fft = abs(np.fft.rfft(all_a_rf))\n",
    "                \n",
    "        angles_rf_data.append(angle(all_h_rf, all_a_rf))\n",
    "        angles_fft_data.append(angle(all_h_fft, all_a_fft))\n",
    "        info_difference_data.append(mean_info/max_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "real_angles_fft = [np.min([a, abs(a - 2*np.pi)]) for a in max_angles_fft.ravel()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "angles_fft_opposite_edges = np.zeros((len(widths), len(widths)))\n",
    "angles_rf_opposite_edges = np.zeros((len(widths), len(widths)))\n",
    "info_difference_opposite_edges = np.zeros((len(widths), len(widths)))\n",
    "\n",
    "center = gaussian(x=space, sigma=median_center_widths[celltype], mu=0.)\n",
    "center /= -np.sum(center)\n",
    "\n",
    "for idw1,w1 in enumerate(widths):\n",
    "    surround1 = gaussian(x=space, sigma=w1, mu=0.)\n",
    "    surround1 /= np.sum(surround1)\n",
    "    for idw2,w2 in enumerate(widths[idw1:]):\n",
    "        surround2 = gaussian(x=space, sigma=w2, mu=0.)\n",
    "        surround2 /= np.sum(surround2)\n",
    "\n",
    "        def rf_model(horz_weight, center_weight):\n",
    "            return center_weight*center + (1-center_weight)*(horz_weight*surround2 + (1-horz_weight)*surround1)\n",
    "\n",
    "        this_map = infos_varying_width[(w1,w2)]\n",
    "        which_fft = np.unravel_index(this_map.argmax(), this_map.shape)\n",
    "        hw = horz_weights[which_fft[0]]\n",
    "        cw = center_weights[which_fft[1]]\n",
    "        \n",
    "        mean_info = np.mean(infos_varying_width[(w1,w2)][:, which_fft[1]])\n",
    "\n",
    "        all_h_rf = rf_model(horz_weights[-1], cw)\n",
    "        all_a_rf = rf_model(horz_weights[0], cw)\n",
    "        \n",
    "        all_h_fft = abs(np.fft.rfft(all_h_rf))\n",
    "        all_a_fft = abs(np.fft.rfft(all_a_rf))\n",
    "        \n",
    "        angle_rf = angle(all_h_rf, all_a_rf)\n",
    "        if np.isnan(angle_rf):\n",
    "            angle_rf = 0\n",
    "            \n",
    "        angle_fft = angle(all_h_fft, all_a_fft)\n",
    "        if np.isnan(angle_fft):\n",
    "            angle_fft = 0\n",
    "                \n",
    "        angles_rf_opposite_edges[idw1, idw2+idw1] = angle_rf\n",
    "        angles_rf_opposite_edges[idw2+idw1, idw1] = angle_rf\n",
    "        angles_fft_opposite_edges[idw1, idw2+idw1] = angle_fft\n",
    "        angles_fft_opposite_edges[idw2+idw1, idw1] = angle_fft\n",
    "        info_difference_opposite_edges[idw1, idw2+idw1] = mean_info/max_info\n",
    "        info_difference_opposite_edges[idw2+idw1, idw1] = mean_info/max_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "radians_to_deg = 360./(2.*np.pi)\n",
    "colors = ['b', 'g', 'r']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "example_ids = []\n",
    "example_angles = []\n",
    "example_info_loss = []\n",
    "flag = [0,0,0]\n",
    "for i,(this_angle,info) in enumerate(zip(angles_fft_opposite_edges.ravel(), info_difference_opposite_edges.ravel())):\n",
    "    angle_deg = radians_to_deg * this_angle\n",
    "    info_loss = 100*(1. - info)\n",
    "    if (angle_deg > 10) and (angle_deg < 20) and (info_loss > 12.) and (info_loss < 50.) and (flag[0] == 0):\n",
    "        print((angle_deg, info_loss))\n",
    "        example_ids.append(np.unravel_index(i, angles_fft_opposite_edges.shape))\n",
    "        example_angles.append(angle_deg)\n",
    "        example_info_loss.append(info_loss)\n",
    "        flag[0] = 1\n",
    "        \n",
    "    if (angle_deg > 40) and (angle_deg < 44) and (info_loss > 30.) and (flag[1] == 0):\n",
    "        print((angle_deg, info_loss))\n",
    "        example_ids.append(np.unravel_index(i, angles_fft_opposite_edges.shape))\n",
    "        example_angles.append(angle_deg)\n",
    "        example_info_loss.append(info_loss)\n",
    "        flag[1] = 1\n",
    "        \n",
    "    if (angle_deg > 26) and (angle_deg < 30) and (info_loss < 2.6) and (flag[2] == 0):\n",
    "        print((angle_deg, info_loss))\n",
    "        example_ids.append(np.unravel_index(i, angles_fft_opposite_edges.shape))\n",
    "        example_angles.append(angle_deg)\n",
    "        example_info_loss.append(info_loss)\n",
    "        flag[2] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "example_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "for idw1, idw2 in example_ids:\n",
    "    print((widths[idw1], widths[idw2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "extreme_rfs = collections.defaultdict(list)\n",
    "center = gaussian(x=space, sigma=median_center_widths[celltype], mu=0.)\n",
    "center /= -np.sum(center)\n",
    "\n",
    "for exi, (idw1, idw2) in enumerate(example_ids):\n",
    "    w1 = widths[idw1]\n",
    "    w2 = widths[idw2]\n",
    "    surround1 = gaussian(x=space, sigma=w1, mu=0.)\n",
    "    surround1 /= np.sum(surround1)\n",
    "    surround2 = gaussian(x=space, sigma=w2, mu=0.)\n",
    "    surround2 /= np.sum(surround2)\n",
    "\n",
    "    def rf_model(horz_weight, center_weight):\n",
    "        return center_weight*center + (1-center_weight)*(horz_weight*surround2 + (1-horz_weight)*surround1)\n",
    "\n",
    "    this_map = infos_varying_width[(w1,w2)]\n",
    "    which_fft = np.unravel_index(this_map.argmax(), this_map.shape)\n",
    "    hw = horz_weights[which_fft[0]]\n",
    "    cw = center_weights[which_fft[1]]\n",
    "\n",
    "    mean_info = np.mean(infos_varying_width[(w1,w2)][:, which_fft[1]])\n",
    "\n",
    "    all_h_rf = rf_model(horz_weights[-1], cw)\n",
    "    all_a_rf = rf_model(horz_weights[0], cw)\n",
    "\n",
    "    all_h_fft = abs(np.fft.rfft(all_h_rf))\n",
    "    all_a_fft = abs(np.fft.rfft(all_a_rf))\n",
    "\n",
    "    # Plot the two RFs\n",
    "    plt.subplot('31%d' %(exi+1))\n",
    "    plt.plot(freqs, all_a_fft/np.max(abs(all_a_fft)), color=colors[exi], linewidth=6)\n",
    "    plt.plot(freqs, all_h_fft/np.max(abs(all_h_fft)), color='k', linewidth=8)\n",
    "    plt.plot(freqs, all_h_fft/np.max(abs(all_h_fft)), color=colors[exi], linewidth=6)\n",
    "    plt.axis('off')\n",
    "    plt.ylim(-.3, 1.1)\n",
    "    plt.xlim(-.1, .6)\n",
    "#     plt.title('Diversity %0.2f$^\\circ$ -  Information loss %0.1f%%' %(this_angle_fft, 100*(1 - this_info)), \n",
    "#               fontsize=18)\n",
    "#     adjust_spines(plt.gca())\n",
    "# plt.savefig('4-2 extreme RFs.png', transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from scipy.signal import convolve2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# contour\n",
    "samples = np.random.multivariate_normal([0,0], np.eye(2), (1000000))\n",
    "angle_bins = radians_to_deg * np.linspace(0, 1.4, 180)\n",
    "info_bins = np.linspace(1.5, 80, 180)\n",
    "count_2d, angles_edges, info_edges = np.histogram2d(radians_to_deg * np.array(angles_fft_data),\n",
    "                                                   100*(1 - np.array(info_difference_data)),\n",
    "                                                   bins=[angle_bins, info_bins])\n",
    "gauss_2d, bins_x, bins_y = np.histogram2d(samples[:,0], samples[:,1], np.linspace(-5,5,30), normed=True)\n",
    "smoothed_count_2d = convolve2d(count_2d, gauss_2d**2, mode='same')\n",
    "smoothed_count_2d[:,0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "eps = 10e-10\n",
    "plt.scatter(radians_to_deg*angles_fft_opposite_edges, 100*(1 - info_difference_opposite_edges.ravel()) + eps, color='k', edgecolor='w', linewidth=0.1, s=15)\n",
    "# plt.scatter(radians_to_deg*np.array(all_arccos),\n",
    "#             100*(1 - np.array(all_info_losses)) + eps, color='k', edgecolor='w', linewidth=0.1, s=15)\n",
    "\n",
    "# contour\n",
    "angle_bins = radians_to_deg * np.linspace(0, 1.4, 180)\n",
    "info_bins = np.linspace(1.5, 80, 180)\n",
    "count_2d, angles_edges, info_edges = np.histogram2d(radians_to_deg * np.array(angles_fft_data),\n",
    "                                                   100*(1 - np.array(info_difference_data)),\n",
    "                                                   bins=[angle_bins, info_bins])\n",
    "\n",
    "# for exi, (idw1, idw2) in enumerate(example_ids):\n",
    "#     plt.scatter(example_angles[exi], example_info_loss[exi], color=colors[exi], linewidth=0.1, s=15)\n",
    "# gauss_2d, bins_x, bins_y = np.histogram2d(samples[:,0], samples[:,1], np.linspace(-5,5,30), normed=True)\n",
    "# smoothed_count_2d = convolve2d(count_2d, gauss_2d**2, mode='same')\n",
    "# smoothed_count_2d[:,0] = 0\n",
    "\n",
    "contour_colors = ['g', 'c', 'b']\n",
    "X, Y = np.meshgrid(angles_edges[:-1] + np.mean(np.diff(angles_edges))/2, \n",
    "                   info_edges[:-1] + np.mean(np.diff(info_edges))/2)\n",
    "CS = plt.contour(X, Y, smoothed_count_2d.T, 3, linewidths=3, alpha=0.9, colors=contour_colors)\n",
    "# contour_counts = CS.levels\n",
    "# for i,c in enumerate(contour_counts):\n",
    "#     plt.text(0.8, 5-1.5*i/2, '%d interneuron cell pairs' %c, fontsize=9, color=contour_colors[i])\n",
    "\n",
    "majorLocator = MultipleLocator(20)\n",
    "majorFormatter = FormatStrFormatter('%d')\n",
    "minorLocator = MultipleLocator(10)\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.xaxis.set_major_locator(majorLocator)\n",
    "ax.xaxis.set_major_formatter(majorFormatter)\n",
    "ax.xaxis.set_minor_locator(minorLocator)\n",
    "\n",
    "\n",
    "plt.xlabel('Diversity (angle)')\n",
    "plt.ylabel('Information loss (percent)')\n",
    "adjust_spines(plt.gca())\n",
    "plt.yscale('log')\n",
    "# plt.ylim(10e-3,80)\n",
    "ax = plt.gca()\n",
    "ax.get_yaxis().get_major_formatter().labelOnlyBase = False\n",
    "plt.tick_params(axis='y', which='minor')\n",
    "ax.yaxis.set_minor_formatter(FormatStrFormatter(\"%.f\"))\n",
    "plt.xlim(-1, 42.5)\n",
    "plt.ylim(1.7, 60)\n",
    "# plt.savefig('12-2 information loss vs diversity with data contour with coarse-grained widths.pdf')\n",
    "# plt.savefig('4-2 information loss vs diversity with contours without extreme rfs.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "example_indices = [[43, 15], \n",
    "                   [96, 11], \n",
    "                   [95, 78]]\n",
    "\n",
    "half_angles_fft = np.copy(angles_fft_opposite_edges)\n",
    "for i in range(angles_fft_opposite_edges.shape[0]):\n",
    "    for j in range(i+1, angles_fft_opposite_edges.shape[1]):\n",
    "        half_angles_fft[j,i] = 1\n",
    "        \n",
    "\n",
    "samples = np.random.multivariate_normal([0,0], np.eye(2), (1000000))\n",
    "gauss_2d, bins_x, bins_y = np.histogram2d(samples[:,0], samples[:,1], np.linspace(-4,4,20), normed=True) \n",
    "smoothed_interneuron_pairs = convolve2d(interneuron_pairs, gauss_2d, mode='same')\n",
    "\n",
    "starting_width_idx = 10\n",
    "ax = plt.gca()\n",
    "im = plt.imshow(radians_to_deg*half_angles_fft[starting_width_idx:, starting_width_idx:], origin='bottom left', \n",
    "                extent=[widths[starting_width_idx], widths[-1], widths[starting_width_idx], widths[-1]],\n",
    "               clim=[0, np.max(np.tril(radians_to_deg*half_angles_fft[starting_width_idx:, starting_width_idx:].T, k=-1))])\n",
    "# plt.title('angle between horz only \\n and ama only ffts', fontsize=9)\n",
    "plt.xlim(widths[starting_width_idx], widths[-1])\n",
    "plt.ylim(widths[starting_width_idx], widths[-1])\n",
    "plt.xlabel('Horizontal component width (degrees)')\n",
    "\n",
    "colors = ['b', 'g', 'r']\n",
    "for exi,ex in enumerate(example_indices):\n",
    "    plt.plot(widths[ex[0]], widths[ex[1]], colors[exi], marker='*', markersize=9, alpha=1)\n",
    "\n",
    "# contour\n",
    "contour_colors = ['g', 'c', 'b']\n",
    "bar_width = np.mean(np.diff(horz_edges))\n",
    "X, Y = np.meshgrid(horz_edges[:-1] + bar_width/2, ama_edges[:-1] + bar_width/2)\n",
    "CS = plt.contour(X, Y, smoothed_interneuron_pairs.T, 3, linewidths=2, alpha=0.8, colors=contour_colors)\n",
    "\n",
    "\n",
    "majorLocator = MultipleLocator(4)\n",
    "majorFormatter = FormatStrFormatter('%d')\n",
    "minorLocator = MultipleLocator(2)\n",
    "\n",
    "ax.xaxis.set_major_locator(majorLocator)\n",
    "ax.xaxis.set_major_formatter(majorFormatter)\n",
    "ax.xaxis.set_minor_locator(minorLocator)\n",
    "ax.yaxis.set_major_locator(majorLocator)\n",
    "ax.yaxis.set_major_formatter(majorFormatter)\n",
    "ax.yaxis.set_minor_locator(minorLocator)\n",
    "\n",
    "# axes\n",
    "ax.spines['left'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.yaxis.set_ticks_position('right')\n",
    "ax.xaxis.set_ticks_position('bottom')\n",
    "plt.ylabel('Amacrine component width (degrees)')\n",
    "divider = make_axes_locatable(ax)\n",
    "cax2 = divider.append_axes(\"right\", size=\"5%\", pad=0.55)\n",
    "cbar = plt.colorbar(im, cax=cax2)\n",
    "cbar.ax.set_ylabel('Diversity (degrees)', fontsize=12)\n",
    "cbar.set_ticks([0, 10, 20, 30, 40])\n",
    "\n",
    "# plt.savefig('lower triangle of diversity smoothed contours with examples degrees 4-2.png', transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
